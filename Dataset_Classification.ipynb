{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b841e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c37468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_psd(bids_root, keywords, nCh=60):\n",
    "    files = glob.glob(os.path.join(bids_root,'sub*','eeg','*'+keywords+\"*\"))\n",
    "    psd = list()\n",
    "    for file in tqdm(files):\n",
    "        data = np.load(file, allow_pickle=True)\n",
    "        psd.append(data)\n",
    "        \n",
    "    return np.array(psd)\n",
    "\n",
    "def extract_psd_seoul(bids_root, keywords, session,  nCh=60):\n",
    "    files = glob.glob(os.path.join(bids_root,'sub*',session, 'eeg','*'+keywords+\"*\"))\n",
    "    psd = list()\n",
    "    for file in tqdm(files):\n",
    "        data = np.load(file, allow_pickle=True)\n",
    "        psd.append(data)\n",
    "        \n",
    "    return np.array(psd)\n",
    "\n",
    "def extract_matrix_new(bids_root, keywords = 'connectivity'):\n",
    "    files = glob.glob(os.path.join(bids_root,'sub*','eeg','*'+keywords+\"*\"))\n",
    "    wpli = list()\n",
    "    iplv = list()\n",
    "    oCC = list()\n",
    "    cplv = list()\n",
    "    name_subj=list()\n",
    "    for file in tqdm(files):\n",
    "        data = np.load(file, allow_pickle=True)\n",
    "        name_subj.append(file.split(\"/\")[7])\n",
    "        \n",
    "        data = np.abs(data).mean(axis=1)\n",
    "        _, nCh, _, nF = data.shape \n",
    "        \n",
    "        for d in data:\n",
    "            for fIdx in range(nF):\n",
    "                np.fill_diagonal(d[...,fIdx], 0)\n",
    "                \n",
    "        _, _, wpli_obs, wpli_sur, oCC_obs, oCC_sur = data\n",
    "        \n",
    "        obs_wpli = np.zeros((nF,))\n",
    "        sur_wpli = np.zeros((nF,))\n",
    "        obs_occ = np.zeros((nF,))\n",
    "        sur_occ = np.zeros((nF,))\n",
    "        for iF in range(nF):\n",
    "            tmp_wpli_obs = wpli_obs[...,iF]\n",
    "            tmp_wpli_sur = wpli_sur[...,iF]\n",
    "            obs_wpli[iF] = np.nanmean(tmp_wpli_obs[tmp_wpli_obs != 0])\n",
    "            sur_wpli[iF] = np.nanmean(tmp_wpli_sur[tmp_wpli_sur != 0])\n",
    "            tmp_occ_obs = oCC_obs[...,iF]\n",
    "            tmp_occ_sur = oCC_sur[...,iF]\n",
    "            obs_occ[iF] = np.mean(tmp_occ_obs[tmp_wpli_obs != 0])\n",
    "            sur_occ[iF] = np.mean(tmp_occ_sur[tmp_wpli_sur != 0])\n",
    "        \n",
    "        wpli.append([obs_wpli,sur_wpli])     \n",
    "        oCC.append([obs_occ,sur_occ]) \n",
    "            \n",
    "    wpli = np.array(wpli)\n",
    "    oCC = np.array(oCC)\n",
    "    return name_subj, wpli, oCC\n",
    "\n",
    "def extract_matrix_seoul(bids_root, keywords = 'connectivity'):\n",
    "    files = glob.glob(os.path.join(bids_root,'sub*','ses-*','eeg','*'+keywords+\"*\"))\n",
    "    wpli = list()\n",
    "    iplv = list()\n",
    "    oCC = list()\n",
    "    cplv = list()\n",
    "    name_subj=list()\n",
    "    for file in tqdm(files):\n",
    "        data = np.load(file, allow_pickle=True)\n",
    "        name_subj.append(file.split(\"/\")[7])\n",
    "        _, _, _, nF = data.shape \n",
    "        for d in data:\n",
    "            for fIdx in range(nF):\n",
    "                np.fill_diagonal(d[...,fIdx], 0)\n",
    "                \n",
    "        _, _, wpli_obs, wpli_sur, oCC_obs, oCC_sur = data\n",
    "                \n",
    "        obs_wpli = np.zeros((nF,))\n",
    "        sur_wpli = np.zeros((nF,))\n",
    "        obs_occ = np.zeros((nF,))\n",
    "        sur_occ = np.zeros((nF,))\n",
    "        for iF in range(nF):\n",
    "            tmp_wpli_obs = wpli_obs[...,iF]\n",
    "            tmp_wpli_sur = wpli_sur[...,iF]\n",
    "            obs_wpli[iF] = np.nanmean(np.abs(tmp_wpli_obs[tmp_wpli_obs != 0]))\n",
    "            sur_wpli[iF] = np.nanmean(np.abs(tmp_wpli_sur[tmp_wpli_sur != 0]))\n",
    "            tmp_occ_obs = oCC_obs[...,iF]\n",
    "            tmp_occ_sur = oCC_sur[...,iF]\n",
    "            obs_occ[iF] = np.mean(np.abs(tmp_occ_obs[tmp_wpli_obs != 0]))\n",
    "            sur_occ[iF] = np.mean(np.abs(tmp_occ_sur[tmp_wpli_sur != 0]))\n",
    "        \n",
    "        wpli.append([obs_wpli,sur_wpli])     \n",
    "        oCC.append([obs_occ,sur_occ])\n",
    "\n",
    "    wpli = np.array(wpli)\n",
    "    oCC = np.array(oCC)\n",
    "    return name_subj, wpli, oCC\n",
    "\n",
    "def create_frequency_axis(f_min=2, f_max= 4, scale_freq ='log', m=1.1):\n",
    "    \n",
    "    if scale_freq == 'log':\n",
    "        f_min_log = math.floor(np.log10(f_min))\n",
    "        f_max_log = math.ceil(np.log10(f_max))\n",
    "        mb = np.logspace(f_min_log, f_max_log, num=40) # Morlet bank \n",
    "        freq_vals = mb[(2.1 < mb) & (mb < 90)] # Frequency of interest\n",
    "        \n",
    "    \n",
    "    elif scale_freq == 'lin':\n",
    "        freq_vals = [f_min]\n",
    "        while freq_vals[~0] < f_max:\n",
    "            freq_vals.append(freq_vals[~0]*m)\n",
    "\n",
    "    freq_labels = [('%.2f'%x) for x in freq_vals]\n",
    "    \n",
    "    return freq_vals, freq_labels\n",
    "\n",
    "\n",
    "def extract_index_and_name(lista, subj, remove=False):\n",
    "    b, index = list(), list()\n",
    "    for i, name in enumerate(lista): \n",
    "        if remove == False:\n",
    "            if name in subj: \n",
    "                b.append(name)\n",
    "                index.append(i)\n",
    "        elif remove == True:\n",
    "            if name not in subj:\n",
    "                b.append(name)\n",
    "                index.append(i)\n",
    "           \n",
    "    return index, b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077dc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbd_root = '/mnt/nas_biolab/data/monica/RBD/RBD_SanMartino/'\n",
    "ctrl_root = '/mnt/nas_biolab/data/monica/RBD/Controls/Controls_SanMartino/'\n",
    "rbd_seoul_root = '/mnt/nas_biolab/data/monica/RBD/RBD_Seoul/'\n",
    "ctrl_seoul_root = '/mnt/nas_biolab/data/monica/RBD/Controls/Controls_Seoul'\n",
    "path_out = '/home/monica/Documents/'\n",
    "\n",
    "freq_vals, freq_labels = create_frequency_axis(f_min=2, f_max=90, scale_freq ='log')\n",
    "freq_vals = freq_vals[:30]\n",
    "\n",
    "\n",
    "freq_pow = np.linspace(0,39,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f08c857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b00de4a1314357a1a6c91b74477b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-aaa901bf4704>:84: RuntimeWarning: Mean of empty slice\n",
      "  obs_wpli[iF] = np.nanmean(np.abs(tmp_wpli_obs[tmp_wpli_obs != 0]))\n",
      "<ipython-input-2-aaa901bf4704>:85: RuntimeWarning: Mean of empty slice\n",
      "  sur_wpli[iF] = np.nanmean(np.abs(tmp_wpli_sur[tmp_wpli_sur != 0]))\n",
      "/home/monica/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/monica/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f0a206765e4d26940b69846eb5e950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f17518b0f94e0eb53064c772da4a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807e454cf8b147ba9790b667b3452450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seoul\n",
    "name_subj_r1_seoul, wplir1_seoul, occr1_seoul = extract_matrix_seoul(bids_root=rbd_seoul_root, keywords = 'ses-01_eeg_connectivity.npy')\n",
    "psdr1_seoul = extract_psd_seoul(bids_root=rbd_seoul_root, keywords ='power2.npy', session='ses-01')\n",
    "\n",
    "idx_subj_r1_seoul, name_subj_r1_seoul = extract_index_and_name(name_subj_r1_seoul, ['sub-18', 'sub-35', 'sub-39'], remove=True)\n",
    "wplir1_seoul = wplir1_seoul[idx_subj_r1_seoul,:,:]\n",
    "occr1_seoul = occr1_seoul[idx_subj_r1_seoul,:,:]\n",
    "psdr1_seoul = psdr1_seoul[idx_subj_r1_seoul,:]\n",
    "\n",
    "name_subj_c1_seoul, wplic1_seoul, occc1_seoul = extract_matrix_seoul(bids_root=ctrl_seoul_root, keywords = 'ses-01_eeg_connectivity.npy')\n",
    "psdc1_seoul = extract_psd_seoul(bids_root=ctrl_seoul_root, keywords ='power2.npy', session='ses-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178d9436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d4462c16454e6fae7d93a7ed63b058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bbde5e6d0946b8aa8acd6dbeb267d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dc380e9f2740d4ac112f89c85c9f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922621409c9e439990ad0b294f66965f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Italy\n",
    "name_subj_r1_italy, wplir1_italy, occr1_italy = extract_matrix_new(bids_root=rbd_root, keywords = 'run-01_connectivity2.npy')\n",
    "psdr1_italy = extract_psd(bids_root=rbd_root, keywords = 'run-01_power2.npy')\n",
    "\n",
    "name_subj_c1_italy, wplic1_italy, occc1_italy = extract_matrix_new(bids_root=ctrl_root, keywords ='run-01_connectivity2.npy')\n",
    "psdc1_italy = extract_psd(bids_root=ctrl_root, keywords = 'run-01_power2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9333d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpli = np.concatenate((wplir1_seoul, wplir1_italy, wplic1_seoul, wplic1_italy))\n",
    "\n",
    "occ = np.concatenate((occr1_seoul, occr1_italy, occc1_seoul, occc1_italy))\n",
    "\n",
    "psd = np.concatenate((psdr1_seoul[:,:,:40].mean(axis=1), psdr1_italy[:,:,:40].mean(axis=1), psdc1_seoul[:,:,:40].mean(axis=1), psdc1_italy[:,:,:40].mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7ffee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list_irbd = np.ones((len(wplir1_italy)+len(wplir1_seoul)), dtype='int64')\n",
    "group_list_ctrl = np.zeros((len(wplic1_italy)+len(wplic1_seoul)), dtype='int64')\n",
    "\n",
    "group_list = np.concatenate((group_list_irbd, group_list_ctrl)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c342c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only PSD\n",
    "df_psd = pd.DataFrame()\n",
    "df_psd['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_pow):\n",
    "    name_col = 'psd_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_psd[name_col] = psd[:,i]\n",
    "\n",
    "df_psd.to_pickle('OnlyPSD.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9436e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only wPLI\n",
    "df_wpli = pd.DataFrame()\n",
    "df_wpli['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'wpli_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_wpli[name_col] = wpli[:,0,i]\n",
    "\n",
    "df_wpli.to_pickle('OnlyWPLI.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2319ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only OCC\n",
    "df_occ = pd.DataFrame()\n",
    "df_occ['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'occ_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_occ[name_col] = occ[:,0,i]\n",
    "\n",
    "df_occ.to_pickle('OnlyOCC.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8239206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSD + wPLI\n",
    "df_psdwpli = pd.DataFrame()\n",
    "df_psdwpli['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_pow):\n",
    "    name_col = 'psd_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_psdwpli[name_col] = psd[:,i]\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'wpli_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_psdwpli[name_col] = wpli[:,0,i]\n",
    "\n",
    "df_psdwpli.to_pickle('PSDWPLI.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de034d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSD + OCC\n",
    "df_psdocc = pd.DataFrame()\n",
    "df_psdocc['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_pow):\n",
    "    name_col = 'psd_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_psdocc[name_col] = psd[:,i]\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'occ_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_psdocc[name_col] = occ[:,0,i]\n",
    "\n",
    "df_psdocc.to_pickle('PSDOCC.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ce8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WPLI + OCC\n",
    "df_wpliocc = pd.DataFrame()\n",
    "df_wpliocc['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'wpli_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_wpliocc[name_col] = wpli[:,0,i]\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'occ_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df_wpliocc[name_col] = occ[:,0,i]\n",
    "\n",
    "df_wpliocc.to_pickle('WPLIOCC.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba5bc51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-481da13cfece>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name_col] = occ[:,0,i]\n"
     ]
    }
   ],
   "source": [
    "# All\n",
    "df = pd.DataFrame()\n",
    "df['Groups'] = group_list\n",
    "\n",
    "for i, freq in enumerate(freq_pow):\n",
    "    name_col = 'psd_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df[name_col] = psd[:,i]\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'wpli_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df[name_col] = wpli[:,0,i]\n",
    "\n",
    "for i, freq in enumerate(freq_vals):\n",
    "    name_col = 'occ_' + str(np.round(freq, decimals=1)) + 'Hz'\n",
    "    df[name_col] = occ[:,0,i]\n",
    "\n",
    "df.to_pickle('AllFeatures.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72228b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
